{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SCO25143\\Downloads\\PyProject\\openenv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the text model (SentenceTransformer) and image model (CLIP)\n",
    "# Text model\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Image model (CLIP)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, preprocess = clip.load('ViT-B/32', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Building the corpus\n",
    "with open('ultimate_games_text.json', 'r') as file:\n",
    "    ultimate_games_text = json.load(file)\n",
    "\n",
    "corpus = []\n",
    "titles = []\n",
    "\n",
    "for game_title, game in ultimate_games_text.items():\n",
    "    titles.append(game_title)\n",
    "    corpus.append(game_title + ':\\n\\n' + '\\n\\n'.join([game[key] for key in game.keys() if key != 'Similar Games']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_with_pictures = dict()\n",
    "pic_path = 'Pictures/'\n",
    "sub_folders = ['#', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
    "               'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "for letter in sub_folders:\n",
    "    for file in os.listdir(pic_path+letter+'/'):\n",
    "        game_name = file.split('_')[0].strip()\n",
    "        if game_name not in games_with_pictures:\n",
    "            games_with_pictures[game_name] = []\n",
    "        games_with_pictures[game_name].append(pic_path+letter+'/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_subs = {'1': ['i', 'one', '1'], 'one': ['i', 'one', '1'], 'i': ['i', 'one', '1'],\n",
    "              '2': ['ii', 'two', '2'], 'two': ['ii', 'two', '2'], 'ii': ['ii', 'two', '2'],\n",
    "              '3': ['iii', 'three', '3'], 'three': ['iii', 'three', '3'], 'iii': ['iii', 'three', '3'],\n",
    "              '4': ['iv', 'four', '4'], 'four': ['iv', 'four', '4'], 'iv': ['iv', 'four', '4'],\n",
    "              '5': ['v', 'five', '5'], 'five': ['v', 'five', '5'], 'v': ['v', 'five', '5'],\n",
    "              '6': ['vi', 'six', '6'], 'six': ['vi', 'six', '6'], 'vi': ['vi', 'six', '6'],\n",
    "              '7': ['vii', 'seven', '7'], 'seven': ['vii', 'seven', '7'], 'vii': ['vii', 'seven', '7'],\n",
    "              '8': ['viii', 'eight', '8'], 'eight': ['viii', 'eight', '8'], 'viii': ['viii', 'eight', '8'],\n",
    "              '9': ['ix', 'nine', '9'], 'nine': ['ix', 'nine', '9'], 'ix': ['ix', 'nine', '9'],\n",
    "              '10': ['x', 'ten', '10'], 'ten': ['x', 'ten', '10'], 'x': ['x', 'ten', '10']}\n",
    "import string\n",
    "alphabet = list(string.ascii_uppercase)\n",
    "import unicodedata\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_match(candidates, title):\n",
    "    best_match = 0\n",
    "    best_index = 0\n",
    "    best_score = 0\n",
    "    # title = ''.join(ch for ch in title if ch.isalnum() or ch == ' ')\n",
    "    title = title.replace('&', 'and')\n",
    "    title_words = [v.translate(str.maketrans('', '', string.punctuation))\n",
    "                       .lower().strip() for v in re.sub('/|_|-|:', ' ', title).split(' ')]\n",
    "    # title_words = [v for v in title_words if v != '']\n",
    "    title_words = [unicodedata.normalize('NFKD', v).encode('ASCII', 'ignore').decode('utf-8')\n",
    "                   for v in title_words if v != '']\n",
    "    for ind, candidate in enumerate(candidates):\n",
    "        try:\n",
    "            # candidate = ''.join(ch for ch in candidate if ch.isalnum() or ch == ' ')\n",
    "            temp_candidate = candidate.replace('video game', '')\n",
    "            temp_candidate = temp_candidate.replace('&', 'and')\n",
    "            candidate_words = [v.translate(str.maketrans('', '', string.punctuation))\n",
    "                                   .lower().strip() for v in re.sub('/|_|-|:', ' ', temp_candidate).split(' ')]\n",
    "            # candidate_words = [v for v in candidate_words if v != '']\n",
    "            candidate_words = [unicodedata.normalize('NFKD', v).encode('ASCII', 'ignore').decode('utf-8')\n",
    "                               for v in candidate_words if v != '']\n",
    "            nb_common_words = 0\n",
    "            if len(title_words) < len(candidate_words):\n",
    "                smaller_title = title_words\n",
    "                bigger_title = copy.copy(candidate_words)\n",
    "            else:\n",
    "                smaller_title = candidate_words\n",
    "                bigger_title = copy.copy(title_words)\n",
    "        \n",
    "            for word in smaller_title:\n",
    "                if word in bigger_title:\n",
    "                    nb_common_words += 1\n",
    "                    bigger_title.remove(word)\n",
    "                elif word in words_subs:\n",
    "                    for sub_word in words_subs[word]:\n",
    "                        if sub_word in bigger_title:\n",
    "                            nb_common_words += 1\n",
    "                            bigger_title.remove(sub_word)\n",
    "            max_length = max(len(title_words), len(candidate_words))\n",
    "            nb_smaller_words = nb_common_words / len(smaller_title)\n",
    "            nb_common_words /= max_length\n",
    "        \n",
    "            # score = (nb_smaller_words + nb_common_words) / 2\n",
    "            if nb_common_words > best_match:\n",
    "                best_match = nb_common_words\n",
    "                best_score = nb_smaller_words\n",
    "                best_index = ind\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return best_index, best_match, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Function to encode text and images\n",
    "projection_layer_image = nn.Linear(512, 384).to(device)\n",
    "\n",
    "def encode_text(text):\n",
    "    return text_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "def encode_images(image_paths):\n",
    "    image_embeddings = []\n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_embedding = clip_model.encode_image(image_input)\n",
    "        image_embeddings.append(image_embedding.cpu())\n",
    "    return torch.stack(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4, Encode everything\n",
    "all_text_embedding = dict()\n",
    "all_images_embedding = dict()\n",
    "all_combined_embedding = dict()\n",
    "games_with_pictures_names = sorted(games_with_pictures.keys())\n",
    "for ind, game in enumerate(tqdm(corpus)):\n",
    "    text_embedding = encode_text(game)\n",
    "    all_text_embedding[titles[ind]] = text_embedding\n",
    "    best_match = get_best_match(games_with_pictures_names, titles[ind])\n",
    "    print(titles[ind], games_with_pictures_names[best_match[0]])\n",
    "    if best_match[1] > 0.7:\n",
    "        try:\n",
    "            image_embeddings = encode_images(games_with_pictures[games_with_pictures_names[best_match[0]]])\n",
    "            image_embeddings = projection_layer_image(image_embeddings.mean(dim=0)[0])\n",
    "            all_images_embedding[titles[ind]] = image_embeddings\n",
    "            combined_embedding = (text_embedding + image_embeddings) / 2\n",
    "            all_combined_embedding[titles[ind]] = combined_embedding\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Function to retrieve similar documents based on a query image or text\n",
    "def retrieve_similar_documents(query, embeddings, num_similar=5):\n",
    "    if isinstance(query, str):  # Query is a text\n",
    "        query_embedding = encode_text(query)\n",
    "    elif isinstance(query, Image.Image):  # Query is an image\n",
    "        image_input = preprocess(query).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            query_embedding = projection_layer_image(clip_model.encode_image(image_input).cpu().mean()[0])\n",
    "    else:\n",
    "        raise ValueError(\"Query should be either text or image.\")\n",
    "    \n",
    "    # Combine query with document embeddings (same as document embedding creation)\n",
    "    # If query is an image, you can combine it with text or average with a set of images, etc.\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, embeddings)\n",
    "    \n",
    "    # Get top similar document indices\n",
    "    top_results = torch.topk(similarities, num_similar)\n",
    "    \n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2523, 2126, 2126, 2300)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_text_embedding), len(all_images_embedding), len(all_combined_embedding), len(games_with_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_text_emb.pkl', 'wb') as file:\n",
    "    pickle.dump(all_text_embedding, file)\n",
    "with open('all_image_emb.pkl', 'wb') as file:\n",
    "    pickle.dump(all_images_embedding, file)\n",
    "with open('all_combined_emb.pkl', 'wb') as file:\n",
    "    pickle.dump(all_combined_embedding, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading embeddings\n",
    "with open('all_text_emb.pkl', 'rb') as file:\n",
    "    all_text_embedding = pickle.load(file)\n",
    "with open('all_image_emb.pkl', 'rb') as file:\n",
    "    all_images_embedding = pickle.load(file)\n",
    "with open('all_combined_emb.pkl', 'rb') as file:\n",
    "    all_combined_embedding = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.9713e-02,  1.6753e-03, -6.9786e-02, -8.0465e-02,  1.9524e-02,\n",
       "        -4.4942e-02, -5.2986e-03,  7.7081e-02,  7.7209e-02,  7.5884e-02,\n",
       "        -2.0209e-02, -6.1343e-02, -1.4746e-02,  7.7292e-02,  3.0814e-02,\n",
       "        -1.0123e-02,  5.9935e-02, -2.6663e-02, -6.0594e-02,  2.5211e-02,\n",
       "         6.4717e-02, -1.1894e-02,  5.2146e-02, -3.0130e-02, -7.4924e-02,\n",
       "         2.8019e-02,  3.4252e-02, -3.2484e-02, -5.9556e-02, -1.3027e-02,\n",
       "        -3.8493e-03, -6.3570e-03, -1.2164e-02, -5.2543e-03,  1.9540e-02,\n",
       "        -5.5622e-02,  1.8956e-02, -3.4239e-02, -7.4016e-02, -1.5767e-03,\n",
       "        -6.9664e-02,  2.4243e-02, -2.2924e-02,  5.8055e-02,  6.1973e-02,\n",
       "        -4.4439e-02, -6.3255e-02,  1.3631e-04, -4.5610e-02, -7.8014e-03,\n",
       "        -2.1684e-02, -9.4209e-02, -1.4638e-02,  1.8784e-02,  1.9070e-02,\n",
       "        -4.8618e-02, -1.8275e-02,  2.3526e-02,  4.0565e-02,  4.1312e-02,\n",
       "        -1.5753e-02, -8.0723e-02,  1.0350e-01,  1.4397e-02,  6.0781e-02,\n",
       "         2.0707e-02,  7.5458e-02, -1.9128e-02, -5.4381e-02, -4.3432e-03,\n",
       "        -6.4933e-02, -3.0524e-02,  8.3157e-03, -3.5385e-02, -6.6175e-02,\n",
       "         6.6243e-03, -2.6167e-02,  6.6745e-03, -5.2021e-02, -9.6488e-03,\n",
       "         9.2520e-02, -9.3500e-02, -1.1118e-01,  3.0429e-02,  3.4043e-03,\n",
       "         3.3104e-02, -2.2411e-02,  6.3058e-02,  1.6599e-02,  3.3929e-02,\n",
       "        -9.0545e-02,  1.8792e-02,  2.3829e-02,  6.1966e-02,  1.1981e-02,\n",
       "        -2.2232e-02, -8.5700e-03, -4.0100e-02, -8.7356e-02,  2.8452e-02,\n",
       "        -1.7149e-02, -1.0382e-02, -3.2899e-03, -2.5842e-02,  9.9209e-02,\n",
       "         3.6548e-03,  7.6988e-03,  3.7904e-02, -4.1318e-02, -1.2912e-02,\n",
       "        -9.8099e-02, -5.2116e-03,  3.2202e-02, -5.0506e-02,  9.1908e-02,\n",
       "         9.1571e-03,  1.0035e-02,  9.9218e-02, -2.4657e-03,  1.0973e-01,\n",
       "         1.0264e-01,  5.2171e-03, -6.3759e-02,  2.7642e-02, -9.9402e-03,\n",
       "         5.3771e-02,  4.4277e-02,  1.1986e-33,  2.9120e-02,  5.6439e-03,\n",
       "         5.9967e-02,  5.2430e-02, -2.7009e-02, -1.9762e-02,  4.6997e-02,\n",
       "         1.1663e-01, -9.1620e-02,  2.4146e-02, -4.5895e-02, -8.3604e-02,\n",
       "        -7.1140e-02,  6.4010e-02,  6.4908e-02,  4.9823e-02,  2.0279e-02,\n",
       "         1.8511e-02,  7.4493e-02,  7.1743e-02,  1.8010e-02,  5.5032e-02,\n",
       "         4.1855e-02, -6.7118e-02, -6.0434e-03,  1.0619e-01, -2.0827e-02,\n",
       "         4.2470e-02,  4.8010e-02, -1.5775e-02, -9.4604e-02, -3.1841e-03,\n",
       "         2.4471e-02, -2.3704e-02,  6.3506e-02, -6.6310e-02, -8.7919e-02,\n",
       "        -4.0677e-02, -5.2196e-02,  2.3058e-02, -3.2577e-03,  3.9464e-02,\n",
       "        -9.7828e-02, -7.8731e-02,  5.0492e-02, -5.3683e-02,  1.1149e-01,\n",
       "        -9.4873e-03, -4.3265e-02,  5.4331e-02, -7.0274e-03,  4.1998e-03,\n",
       "        -6.4518e-02,  4.9442e-03, -3.0690e-02, -3.6203e-02,  1.5038e-02,\n",
       "        -7.4945e-02, -7.3904e-02,  3.9568e-02,  1.5674e-02, -3.1122e-02,\n",
       "        -5.0928e-02,  4.8225e-02, -9.3290e-03,  5.3002e-02,  7.0997e-03,\n",
       "         3.4569e-03, -6.5974e-02,  1.0589e-02, -2.8309e-02, -1.8535e-02,\n",
       "         5.2351e-02, -7.8745e-03,  3.9745e-02, -5.9283e-03,  2.9511e-02,\n",
       "         4.2299e-02, -7.9595e-02, -2.0621e-02, -2.8849e-02,  6.1149e-02,\n",
       "         2.1957e-02,  3.3770e-02, -2.9150e-03,  1.7766e-03,  4.0924e-02,\n",
       "         1.3986e-03,  4.4835e-02,  8.8308e-02, -4.2013e-02, -1.1898e-01,\n",
       "        -5.3461e-02,  2.3836e-02,  1.1531e-02, -2.4481e-33,  1.5028e-02,\n",
       "        -8.6635e-02, -9.6308e-02,  1.8158e-02,  3.8396e-02, -1.5157e-02,\n",
       "        -1.3552e-01,  2.5470e-02,  7.5330e-02, -2.8822e-02, -9.2080e-03,\n",
       "         2.7758e-02,  9.6618e-02,  4.5260e-02,  3.0083e-02, -7.2173e-02,\n",
       "         4.1815e-03, -1.8394e-02,  9.0745e-02, -3.3471e-02,  7.1448e-02,\n",
       "        -3.6802e-02, -2.6583e-03,  1.3747e-02,  7.7927e-02,  6.6510e-02,\n",
       "        -2.0107e-02,  2.9633e-02,  1.4533e-02,  5.8639e-02,  5.8456e-02,\n",
       "        -1.2630e-02,  2.1349e-02,  4.4281e-02, -5.0932e-02,  6.9111e-02,\n",
       "         8.8751e-03, -3.9229e-02,  2.8194e-02, -4.4753e-02, -4.8156e-02,\n",
       "         2.5461e-02, -1.0099e-01, -4.2424e-03, -7.1051e-02,  2.2192e-02,\n",
       "         7.3825e-02,  4.8814e-03,  3.5969e-02, -2.5978e-02, -2.6696e-03,\n",
       "         3.1429e-02, -7.0354e-02, -7.6318e-02, -5.6742e-02, -3.2724e-02,\n",
       "        -1.1685e-01, -3.8588e-03,  3.9604e-02,  1.7697e-02,  5.7022e-02,\n",
       "        -4.3749e-03, -9.1794e-03, -3.9302e-02, -5.1511e-02, -1.1991e-04,\n",
       "        -6.2840e-03,  1.1944e-01,  3.9543e-02, -6.4388e-02,  3.4585e-03,\n",
       "        -3.6533e-03, -8.3356e-02,  1.2032e-02, -7.6404e-04, -1.3553e-02,\n",
       "        -8.3763e-02, -3.8521e-02, -4.5036e-02, -2.9241e-02, -2.5807e-02,\n",
       "        -8.5348e-03,  3.7987e-02,  5.2005e-02,  2.7570e-02,  8.6050e-02,\n",
       "         3.8601e-02,  6.9132e-02, -2.3468e-02, -4.3767e-02, -1.1124e-03,\n",
       "         7.1240e-02, -4.0532e-02,  1.0152e-01, -4.0183e-02, -6.9862e-08,\n",
       "         4.8205e-02,  3.8258e-02, -2.1722e-02, -3.8501e-02, -1.2010e-02,\n",
       "        -2.6062e-02,  1.9933e-02, -8.1898e-03,  3.1464e-02,  8.4003e-02,\n",
       "         3.7351e-02, -1.3981e-02, -6.5321e-03, -1.9709e-02, -1.7062e-03,\n",
       "         1.8866e-02, -2.3885e-02, -3.2304e-02,  1.8891e-02,  8.4575e-02,\n",
       "         6.1576e-02, -5.6085e-02,  5.4525e-03, -1.8434e-01,  4.2177e-02,\n",
       "        -7.6558e-02, -2.6917e-02,  2.6107e-02,  3.3991e-02,  7.2111e-02,\n",
       "         7.3250e-02, -7.7264e-02,  1.9050e-02,  2.6726e-02, -2.8434e-02,\n",
       "        -1.8939e-02,  7.7921e-02,  4.1958e-02,  2.8140e-02, -1.3890e-02,\n",
       "        -4.8472e-02,  4.7345e-02, -7.3785e-02,  3.9211e-02, -1.9703e-02,\n",
       "        -2.6095e-02, -3.1978e-02, -8.3266e-02, -3.3838e-02, -3.7716e-02,\n",
       "         1.3636e-02,  3.0217e-02, -9.0300e-02,  2.2391e-02,  1.5971e-01,\n",
       "         1.0242e-02, -8.7090e-04,  3.6738e-02, -9.7795e-03,  4.3280e-02,\n",
       "         4.4796e-02, -9.5035e-02, -1.8251e-02,  4.8571e-02])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_text_embedding.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top similar documents based on text query:\n",
      "Demon Turf - Document 478 with similarity score: 0.6054\n",
      "Metamorphosis - Document 1246 with similarity score: 0.5870\n",
      "TUNIC - Document 2036 with similarity score: 0.5795\n",
      "DYSMANTLE - Document 423 with similarity score: 0.5678\n",
      "Blue Fire - Document 243 with similarity score: 0.5663\n",
      "BIOMORPH - Document 151 with similarity score: 0.5580\n",
      "Souldiers - Document 1888 with similarity score: 0.5579\n",
      "Hollow Knight - Document 939 with similarity score: 0.5464\n",
      "Gloomhaven - Document 813 with similarity score: 0.5426\n",
      "Dust An Elysian Tail - Document 599 with similarity score: 0.5422\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Search by text\n",
    "query_text = \"Forge your own path in this game. An epic action adventure through a vast ruined kingdom of insects and heroes. Explore twisting caverns, battle tainted creatures and befriend bizarre bugs, all in a classic, hand-drawn 2D style. \"\n",
    "titles = sorted(all_text_embedding.keys())\n",
    "embeddings = [all_text_embedding[v].numpy() for v in titles]\n",
    "similar_docs_text = retrieve_similar_documents(query_text, embeddings, num_similar=10)\n",
    "\n",
    "# Search by image\n",
    "# query_image = Image.open('images/query_cat.jpg')  # This should be your query image\n",
    "# similar_docs_image = retrieve_similar_documents(query_image, num_similar=3)\n",
    "\n",
    "# Output the results for both\n",
    "print(\"\\nTop similar documents based on text query:\")\n",
    "for idx, score in zip(similar_docs_text.indices[0], similar_docs_text.values[0]):\n",
    "    print(titles[idx.item()], f\"- Document {idx.item() + 1} with similarity score: {score.item():.4f}\")\n",
    "\n",
    "# print(\"\\nTop similar documents based on image query:\")\n",
    "# for idx, score in zip(similar_docs_image.indices[0], similar_docs_image.values[0]):\n",
    "#     print(f\"- Document {idx.item() + 1} with similarity score: {score.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
