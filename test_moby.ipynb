{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import string\n",
    "import urllib\n",
    "import asyncio\n",
    "import requests\n",
    "import unicodedata\n",
    "import editdistance\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "alphabet = list(string.ascii_uppercase)\n",
    "\n",
    "base_moby = 'https://www.mobygames.com/'\n",
    "\n",
    "soup_headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) '\n",
    "              'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "              'Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "words_subs = {'1': ['i', 'one', '1'], 'one': ['i', 'one', '1'], 'i': ['i', 'one', '1'],\n",
    "              '2': ['ii', 'two', '2'], 'two': ['ii', 'two', '2'], 'ii': ['ii', 'two', '2'],\n",
    "              '3': ['iii', 'three', '3'], 'three': ['iii', 'three', '3'], 'iii': ['iii', 'three', '3'],\n",
    "              '4': ['iv', 'four', '4'], 'four': ['iv', 'four', '4'], 'iv': ['iv', 'four', '4'],\n",
    "              '5': ['v', 'five', '5'], 'five': ['v', 'five', '5'], 'v': ['v', 'five', '5'],\n",
    "              '6': ['vi', 'six', '6'], 'six': ['vi', 'six', '6'], 'vi': ['vi', 'six', '6'],\n",
    "              '7': ['vii', 'seven', '7'], 'seven': ['vii', 'seven', '7'], 'vii': ['vii', 'seven', '7'],\n",
    "              '8': ['viii', 'eight', '8'], 'eight': ['viii', 'eight', '8'], 'viii': ['viii', 'eight', '8'],\n",
    "              '9': ['ix', 'nine', '9'], 'nine': ['ix', 'nine', '9'], 'ix': ['ix', 'nine', '9'],\n",
    "              '10': ['x', 'ten', '10'], 'ten': ['x', 'ten', '10'], 'x': ['x', 'ten', '10']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_string(str_obj):\n",
    "    str_obj = str_obj.replace('&', 'and')\n",
    "    title_words = [v.translate(str.maketrans('', '', string.punctuation))\n",
    "                       .lower().strip() for v in re.sub('/|_|-|:', ' ', str_obj).split(' ')]\n",
    "    title_words = [unicodedata.normalize('NFKD', v).encode('ASCII', 'ignore').decode('utf-8')\n",
    "                   for v in title_words if v != '']\n",
    "    return title_words\n",
    "\n",
    "\n",
    "def get_best_match(candidates, title):\n",
    "    best_match = 0\n",
    "    best_index = 0\n",
    "    best_score = 0\n",
    "\n",
    "    title_words = format_string(title)\n",
    "    \n",
    "    for ind, candidate in enumerate(candidates):\n",
    "\n",
    "        temp_candidate = candidate.replace('video game', '')\n",
    "        candidate_words = format_string(temp_candidate)\n",
    "        \n",
    "        nb_common_words = 0\n",
    "        if len(title_words) < len(candidate_words):\n",
    "            smaller_title = title_words\n",
    "            bigger_title = copy.copy(candidate_words)\n",
    "        else:\n",
    "            smaller_title = candidate_words\n",
    "            bigger_title = copy.copy(title_words)\n",
    "\n",
    "        for word in smaller_title:\n",
    "            if word in bigger_title:\n",
    "                nb_common_words += 1\n",
    "                bigger_title.remove(word)\n",
    "            elif word in words_subs:\n",
    "                for sub_word in words_subs[word]:\n",
    "                    if sub_word in bigger_title:\n",
    "                        nb_common_words += 1\n",
    "                        bigger_title.remove(sub_word)\n",
    "        max_length = max(len(title_words), len(candidate_words))\n",
    "        nb_smaller_words = nb_common_words / len(smaller_title)\n",
    "        nb_common_words /= max_length\n",
    "\n",
    "        # score = (nb_smaller_words + nb_common_words) / 2\n",
    "        if nb_common_words > best_match:\n",
    "            best_match = nb_common_words\n",
    "            best_score = nb_smaller_words\n",
    "            best_index = ind\n",
    "\n",
    "    return best_index, best_match, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_edit_distance(candidates, title):\n",
    "    best_index = 0\n",
    "    best_score = 2000\n",
    "\n",
    "    new_title = ' '.join(format_string(title))\n",
    "    for ind, candidate in enumerate(candidates):\n",
    "\n",
    "        temp_candidate = candidate.replace('video game', '')\n",
    "        temp_candidate = ' '.join(format_string(temp_candidate))\n",
    "        distance = editdistance.distance(new_title, temp_candidate)\n",
    "        if distance < best_score:\n",
    "            best_score = distance\n",
    "            best_index = ind\n",
    "\n",
    "    return best_index, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url, steam=False):\n",
    "    if steam:\n",
    "        \n",
    "        webpage = requests.get(url, headers=soup_headers)\n",
    "    else:\n",
    "        webpage = requests.get(url, headers=soup_headers)\n",
    "    return BeautifulSoup(webpage.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moby_url(title):\n",
    "    temp_title = title\n",
    "    score, edist_score = 0, 0\n",
    "    url, edist_url = '', ''\n",
    "    success = True\n",
    "    try:\n",
    "        base_url = 'https://www.mobygames.com/search/?q='\n",
    "        url = base_url + temp_title\n",
    "\n",
    "        soup = get_soup(url)\n",
    "        urls = []\n",
    "        table_elem = soup.find_all('table')[0]\n",
    "        search_results = table_elem.find_all('b')\n",
    "        candidates = []\n",
    "        for result in search_results:\n",
    "            search_title = result.text\n",
    "            urls.append(result.find('a').attrs['href'])\n",
    "            candidates.append(search_title)\n",
    "\n",
    "        print(candidates)\n",
    "        best_candidate = get_best_match(candidates, title)\n",
    "        temp_title = candidates[best_candidate[0]]\n",
    "        score = best_candidate[1]\n",
    "        url = urls[best_candidate[0]]\n",
    "        \n",
    "        best_edist_candidate = get_best_edit_distance(candidates, title)\n",
    "        edist_url = urls[best_edist_candidate[0]]\n",
    "        edist_score = best_edist_candidate[1]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        success = False\n",
    "\n",
    "    return {'moby-title': temp_title,\n",
    "            'moby-score': score, 'moby-edist-score': edist_score,\n",
    "            'moby-url': url, 'moby-edist-url': edist_url,'moby-success': success}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moby_info(url, score):\n",
    "    soup = get_soup(url)\n",
    "    if score >= 0.7:\n",
    "        title_elem = soup.find('h1', {'class': 'mb-0'})\n",
    "        title = title_elem.text\n",
    "        next_elem = title_elem.find_next('div')\n",
    "        if 'aka' in next_elem.text:\n",
    "            title_aliases = next_elem.text.split('aka:\\n')[1].strip()\n",
    "            next_elem = next_elem.find_next('div')\n",
    "        title_id = next_elem.text.split('Moby ID:' )[1].strip()\n",
    "        print(title, '#', title_aliases, '#', title_id)\n",
    "\n",
    "        temp_div = soup.find('div', {'class': 'info-release'})\n",
    "        temp_dl = temp_div.find('dl')\n",
    "        temp_elems = temp_dl.find_all(recursive=False)\n",
    "        for el in range(0, len(temp_elems), 2):\n",
    "            dt_elem = temp_elems[el].text\n",
    "            dd_elem = temp_elems[el+1].text\n",
    "            if 'Released' in dt_elem:\n",
    "                release_date = dd_elem.split('on')[0].strip()\n",
    "                continue\n",
    "            if 'Publishers' in dt_elem:\n",
    "                publishers = dd_elem.strip()\n",
    "                continue\n",
    "            if 'Developers' in dt_elem:\n",
    "                developers = dd_elem.strip()\n",
    "                continue\n",
    "        print(release_date, '#', publishers, '#', developers)\n",
    "\n",
    "        temp_div = soup.find('div', {'class': 'info-score'})\n",
    "        temp_dl = temp_div.find('dl')\n",
    "        temp_elems = temp_dl.find_all(recursive=False)\n",
    "        for el in range(0, len(temp_elems), 2):\n",
    "            dt_elem = temp_elems[el].text\n",
    "            dd_elem = temp_elems[el+1].text\n",
    "            if 'Moby Score' in dt_elem:\n",
    "                dd_split = dd_elem.split('#')\n",
    "                moby_score = dd_split[0].strip()\n",
    "                moby_rank = dd_split[1].split(' of')[0].strip()\n",
    "                continue\n",
    "            if 'Critics' in dt_elem:\n",
    "                dd_split = dd_elem.split('%')\n",
    "                critics_score = dd_split[0].strip()\n",
    "                critics_count = dd_split[1].replace('(', '').replace(')', '').strip()\n",
    "                continue\n",
    "        print(moby_score, '#', moby_rank, '#', critics_score, '#', critics_count)\n",
    "\n",
    "        temp_div = soup.find('div', {'class': 'info-genres'})\n",
    "        temp_dl = temp_div.find('dl')\n",
    "        temp_elems = temp_dl.find_all(recursive=False)\n",
    "        genre_dict = dict()\n",
    "        for el in range(0, len(temp_elems), 2):\n",
    "            dt_elem = temp_elems[el].text\n",
    "            dd_elem = temp_elems[el+1].get_text(' ; ')\n",
    "            genre_dict[dt_elem] = dd_elem\n",
    "        print(genre_dict)\n",
    "\n",
    "        try:\n",
    "            description = soup.find('section', {'id': 'gameOfficialDescription'}).text.replace('\\n\\n', '\\n').strip()\n",
    "        except AttributeError as _:\n",
    "            description = soup.find('section', {'id': 'gameDescription'}).text.replace('\\n\\n', '\\n').strip()\n",
    "        print(description)\n",
    "\n",
    "        tags_elem = soup.find('section', {'id': 'gameGroups'})\n",
    "        tags_li = tags_elem.find_all('li')\n",
    "        tags = ' ; '.join([v.text.strip() for v in tags_li])\n",
    "        print(tags)\n",
    "\n",
    "        review_section = soup.find('section', {'id': 'critic-reviews'})\n",
    "        reviews_elem = json.loads(str(review_section.find('critic-reviews').attrs.get(':reviews')))\n",
    "        reviews_dict = dict()\n",
    "        for review in reviews_elem:\n",
    "            journal = review['source']['name']\n",
    "            if journal not in reviews_dict:\n",
    "                reviews_dict[journal] = []\n",
    "            reviews_dict[journal].append({'review': review['citation'], 'score': review['normalized_score']}) \n",
    "        print(reviews_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "{'moby-title': '13 Sentinels - Aegis Rim', 'moby-score': 0, 'moby-edist-score': 0, 'moby-url': 'https://www.mobygames.com/search/?q=13 Sentinels - Aegis Rim', 'moby-edist-url': '', 'moby-success': False}\n"
     ]
    }
   ],
   "source": [
    "moby_best = get_moby_url('13 Sentinels - Aegis Rim')\n",
    "print(moby_best)\n",
    "get_moby_info(moby_best['moby-url'], moby_best['moby-score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
