{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import colorsys\n",
    "import webcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image, ImageOps, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires a modified webcolors _conversion and _init__ code\n",
    "\n",
    "css_color_map = webcolors.get_color_map(webcolors.CSS3)\n",
    "css_rgbs = []\n",
    "html_color_map = webcolors.get_color_map(webcolors.HTML4)\n",
    "html_rgbs = []\n",
    "for key in css_color_map.keys():\n",
    "    css_rgbs.append(webcolors.hex_to_rgb(key))\n",
    "for key in html_color_map.keys():\n",
    "    html_rgbs.append(webcolors.hex_to_rgb(key))\n",
    "\n",
    "css_numpy_arr = np.array([[v[0], v[1], v[2]] for v in css_rgbs])\n",
    "html_numpy_arr = np.array([[v[0], v[1], v[2]] for v in html_rgbs])\n",
    "color_arrays = {webcolors.CSS3: css_numpy_arr, webcolors.HTML4: html_numpy_arr}\n",
    "\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return np.linalg.norm(a - b, axis=-1)\n",
    "\n",
    "\n",
    "def manhattan_distance(a, b):\n",
    "    return np.sum(np.abs(a - b), axis=-1)\n",
    "\n",
    "\n",
    "def closest_color(rgb_color, color_base=webcolors.CSS3):\n",
    "    min_colors = {}\n",
    "    for key, name in webcolors.get_color_map(color_base).items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - rgb_color[0]) ** 2\n",
    "        gd = (g_c - rgb_color[1]) ** 2\n",
    "        bd = (b_c - rgb_color[2]) ** 2\n",
    "        min_colors[(rd + gd + bd)] = name\n",
    "    return min_colors[min(min_colors.keys())]\n",
    "\n",
    "\n",
    "def get_color_name(rgb_tuple, base_color=webcolors.CSS3):\n",
    "    try:\n",
    "        # Convert RGB to hex\n",
    "        hex_value = webcolors.rgb_to_hex(rgb_tuple)\n",
    "        # Get the color name directly\n",
    "        return webcolors.hex_to_name(hex_value, base_color)\n",
    "    except ValueError:\n",
    "        # If exact match not found, find the closest color\n",
    "        return closest_color(rgb_tuple, base_color)\n",
    "    \n",
    "\n",
    "def find_closest_points_euclidean(image_array, color_base):\n",
    "    color_dict = dict()\n",
    "    for n_point in image_array:\n",
    "        for pixel in n_point:\n",
    "            # Compute Euclidean distance to all points in M\n",
    "            distances = euclidean_distance(color_arrays[color_base], pixel)\n",
    "            # Get index of the minimum distance\n",
    "            closest_index = np.argmin(distances)\n",
    "            closest_color = color_arrays[color_base][closest_index]\n",
    "            color_name = webcolors.rgb_to_name((closest_color[0], closest_color[1], closest_color[2]), color_base)\n",
    "            color_dict[color_name] = color_dict.get(color_name, 0) + 1\n",
    "    return color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "color_ranges = {\n",
    "    'red':    [[200, 0, 0], [255, 100, 100]],\n",
    "    'green':  [(0, 200, 0), (100, 255, 100)],\n",
    "    'blue':   [(0, 0, 200), (100, 100, 255)],\n",
    "    'yellow': [(200, 200, 0), (255, 255, 100)],\n",
    "    'cyan':   [(0, 200, 200), (100, 255, 255)],\n",
    "    'magenta': [(200, 0, 200), (255, 100, 255)],\n",
    "    'orange': [(200, 100, 0), (255, 200, 80)],  # Orange range\n",
    "    'indigo': [(75, 0, 130), (100, 50, 150)],   # Indigo range\n",
    "    'black':  [(0, 0, 0), (50, 50, 50)],\n",
    "    'white':  [(200, 200, 200), (255, 255, 255)]\n",
    "    } \n",
    "'''\n",
    "\n",
    "def resize_image(img, width=180, height=240):\n",
    "    resized_image = img.resize((width, height)).convert('RGB')\n",
    "    return resized_image\n",
    "\n",
    "def add_border(img, color=(0, 0, 0), border_width=10):\n",
    "    return ImageOps.expand(img, border=border_width, fill=color)\n",
    "\n",
    "def get_avg_rgb(img):\n",
    "    image_np = np.array(img)\n",
    "    avg_color = np.mean(image_np, axis=(0, 1), dtype=int)  # Average across pixels\n",
    "    return avg_color\n",
    "\n",
    "def rgb_to_hsv(rgb):\n",
    "    r, g, b = rgb / 255.0\n",
    "    h, s, v = colorsys.rgb_to_hsv(r, g, b)\n",
    "    if s < 0.01:  # Close to 0 saturation means black, white, or gray\n",
    "        h = -1 \n",
    "    else:\n",
    "        h *= 360\n",
    "    return h, s, v\n",
    "\n",
    "def rgb_to_hls(rgb):\n",
    "    r, g, b = rgb / 255.0\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    if s < 0.01:  # Close to 0 saturation means black, white, or gray\n",
    "        h = -1 \n",
    "    else:\n",
    "        h *= 360\n",
    "    return h, l, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_image_colors_numpy(img):\n",
    "    css_color_dict = find_closest_points_euclidean(img, webcolors.CSS3)\n",
    "    html_color_dict = find_closest_points_euclidean(img, webcolors.HTML4)\n",
    "    return css_color_dict, html_color_dict\n",
    "\n",
    "\n",
    "def count_image_colors(img):\n",
    "    css_color_dict = dict()\n",
    "    html_color_dict = dict()\n",
    "    for row in img:\n",
    "        for pixel in row:\n",
    "            css_color_name = get_color_name(pixel, webcolors.CSS3)\n",
    "            html_color_name = get_color_name(pixel, webcolors.HTML4)\n",
    "            css_color_dict[css_color_name] = css_color_dict.get(css_color_name, 0) + 1\n",
    "            html_color_dict[html_color_name] = html_color_dict.get(html_color_name, 0) + 1\n",
    "    return css_color_dict, html_color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('Covers 180/')[:1]\n",
    "tt = count_image_colors_numpy(np.asarray(Image.open('Covers 180/' + image_list[0]), dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('Covers/')\n",
    "# images_objs = [Image.open('Covers 1200/' + img) for img in image_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ultimate_games.json', 'r', encoding='utf-8') as file:\n",
    "    ultimate_games = json.load(file)\n",
    "with open('game_platform_franchise.txt', 'r', encoding='utf-8') as file:\n",
    "    franchise_games = file.readlines()\n",
    "\n",
    "clean_images_list = [v.replace('_Cover.jpg', '') for v in image_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = dict()\n",
    "for line in franchise_games:\n",
    "    line_feat = line.replace('\\n', '').split('\\t')\n",
    "    line_franchise_1 = line_feat[0]\n",
    "    line_franchise_2 = line_feat[1]\n",
    "    line_developer = line_feat[2]\n",
    "    game_title = line_feat[3]\n",
    "    image_title = line_feat[4]\n",
    "    \n",
    "    if line_franchise_2 != '':\n",
    "        if line_franchise_2 not in image_dict:\n",
    "            image_dict[line_franchise_2] = []\n",
    "        image_dict[line_franchise_2].append(image_title)\n",
    "        continue\n",
    "\n",
    "    if line_franchise_1 != '':\n",
    "        if line_franchise_1 not in image_dict:\n",
    "            image_dict[line_franchise_1] = []\n",
    "        image_dict[line_franchise_1].append(image_title)\n",
    "        continue\n",
    "\n",
    "    if line_developer != '':\n",
    "        if line_developer not in image_dict:\n",
    "            image_dict[line_developer] = []\n",
    "        image_dict[line_developer].append(image_title)\n",
    "        continue\n",
    "\n",
    "    image_dict[game_title] = [image_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_images = []\n",
    "for v in sorted(list(image_dict.values()), key=len, reverse=True):\n",
    "    sorted_images.extend(v)\n",
    "\n",
    "for ind in range(len(sorted_images)):\n",
    "    sorted_images[ind] += '_Cover.jpg'\n",
    "\n",
    "images_objs = [Image.open('Covers/' + img) for img in sorted_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in image_list:\n",
    "    img_obj = Image.open('Covers/' + img)\n",
    "    for sz in [(864, 1269), (1200, 1600), (180, 240)]:\n",
    "        resized_image = resize_image(img_obj, sz[0], sz[1])\n",
    "        resized_image.save('Covers ' + str(sz[0]) + '/' + img.replace('_Cover', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_count = 4\n",
    "image_hor_list = []\n",
    "for offset in range(0, len(images_objs), horizontal_count):\n",
    "    image_hor_list.append(np.hstack([img for img in images_objs[offset: offset+horizontal_count]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_count = 4\n",
    "image_ver_list = []\n",
    "for offset in range(0, len(image_hor_list), vertical_count):\n",
    "    image_ver_list.append(np.vstack([img for img in image_hor_list[offset: offset+vertical_count]]))\n",
    "    # new_image.save('Posters/Trifecta_vertical.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, img in enumerate(image_ver_list):\n",
    "    imgs_poster = Image.fromarray(img)\n",
    "    imgs_poster.save('Posters/poster_' + str(ind) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('Covers Best/')\n",
    "poster_size = 16\n",
    "random.shuffle(image_list)\n",
    "poster_count = 5000\n",
    "for offset in range(0, len(image_list), poster_size):\n",
    "    images_objs = [Image.open('Covers Best/' + img) for img in image_list[offset: offset+poster_size]]\n",
    "    converters = [ImageEnhance.Color(v) for v in images_objs]\n",
    "    image_obj = [v.enhance(1.5) for v in converters]\n",
    "    images_objs = [ImageOps.expand(img, border=20, fill='yellow') for img in images_objs]\n",
    "    horizontal_count = 4\n",
    "    image_hor_list = []\n",
    "    for offset in range(0, len(images_objs), horizontal_count):\n",
    "        image_hor_list.append(np.hstack([img for img in images_objs[offset: offset+horizontal_count]]))\n",
    "\n",
    "    poster = np.vstack([img for img in image_hor_list])\n",
    "    poster = Image.fromarray(poster)\n",
    "    poster.save('Posters/poster_' + str(poster_count) + '.jpg')\n",
    "    poster_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('Covers 180/')\n",
    "color_info_dict = dict()\n",
    "for ind, img in enumerate(image_list):\n",
    "    print(img)\n",
    "    image_obj = Image.open('Covers 180/' + img)\n",
    "    image_obj = np.asarray(image_obj, dtype=int)\n",
    "    r_g_b = get_avg_rgb(image_obj)\n",
    "    h1, s1, v1 = rgb_to_hsv(r_g_b)\n",
    "    _, l1, s2 = rgb_to_hls(r_g_b)\n",
    "    css_dict, html_dict = count_image_colors_numpy(image_obj)\n",
    "    color_info_dict[img] = {'r': r_g_b[0], 'g': r_g_b[1], 'b': r_g_b[2],\n",
    "                            'hue': round(h1, 2), 'sat_1': round(s1, 2), 'value': round(v1),\n",
    "                            'lumo': round(l1, 2), 'sat_2': round(s2, 2)}\n",
    "    color_info_dict[img]['css'] = css_dict\n",
    "    color_info_dict[img]['html'] = html_dict\n",
    "\n",
    "'''\n",
    "for ind, arr in enumerate(color_mean_list):\n",
    "    hsv = colorsys.rgb_to_hsv(arr[0], arr[1], arr[2])\n",
    "    hsl = colorsys.rgb_to_hls(arr[0], arr[1], arr[2])\n",
    "    print(ind, arr[0], arr[1], arr[2], hsv[0], hsv[1], hsv[2], hsl[0], hsl[1], hsl[2])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': 130, 'g': 130, 'b': 130, 'hue': -1, 'sat_1': 0.0, 'value': 1, 'lumo': 0.51, 'sat_2': 0.0, 'css': {'white': 8025, 'whitesmoke': 2474, 'snow': 1412, 'silver': 1584, 'gray': 2131, 'darkgray': 4970, 'lightgray': 1145, 'ghostwhite': 324, 'gainsboro': 1544, 'lavender': 452, 'lightslategray': 1280, 'dimgray': 1734, 'black': 15123, 'darkslategray': 1002}, 'html': {'white': 13263, 'silver': 4833, 'gray': 8772, 'pink': 582, 'black': 15750}}\n"
     ]
    }
   ],
   "source": [
    "new_dict = dict()\n",
    "for game, val in color_info_dict.items():\n",
    "    new_dict[game] = json.loads(str(val).replace(\"'\", '\"'))\n",
    "with open('cover_colors.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(new_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_avg = pd.read_csv('Colors.csv', index_col=False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('Covers 864/')\n",
    "colors_ds = pd.read_csv('colors-manual-order.csv', index_col=None).values\n",
    "\n",
    "for ind, image in enumerate(colors_ds):\n",
    "    image_path = image[0] + '.jpg'\n",
    "    image_obj = Image.open('Covers 864/' + image_path)\n",
    "    image_obj = ImageOps.expand(image_obj.resize((864, 1269)).convert('RGB'), border=20, fill='red')\n",
    "    # converter = ImageEnhance.Color(image_obj)\n",
    "    # image_obj = converter.enhance(1.5)\n",
    "    image_obj.save('Covers Test/' +  str(ind+1) + ' ' + image[0] + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('Covers 180/')\n",
    "for image in image_list:\n",
    "    image_obj = Image.open('Covers 180/' + image)\n",
    "    image_obj = np.asarray(image_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_pixel_features(image_path):\n",
    "    \"\"\"\n",
    "    Extract all pixel RGB values from an image as the feature set.\n",
    "    This will flatten the image into a 2D array of RGB pixels.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_np = np.array(image)  # Convert to NumPy array\n",
    "    return image_np.reshape(-1, 3)  # Flatten to a 2D array of pixels (N, 3)\n",
    "\n",
    "\n",
    "def cluster_images_by_pixels(folder_path, n_clusters=5):\n",
    "    \"\"\"\n",
    "    Cluster images based on the RGB values of all pixels using k-means.\n",
    "    :param folder_path: Path to the folder containing images.\n",
    "    :param n_clusters: Number of clusters for pixel-level k-means.\n",
    "    \"\"\"\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('jpg', 'png', 'jpeg'))]\n",
    "    image_features = []  # Store features for each image\n",
    "\n",
    "    for img in image_files:\n",
    "        img_path = os.path.join(folder_path, img)\n",
    "        pixel_features = get_image_pixel_features(img_path)  # Get all pixel colors\n",
    "        kmeans_pixels = KMeans(n_clusters=5, random_state=42).fit(pixel_features)\n",
    "        cluster_centers = kmeans_pixels.cluster_centers_  # Centroids represent dominant colors\n",
    "        image_features.append(cluster_centers.flatten())  # Flatten for clustering images\n",
    "    \n",
    "    # Cluster images based on their pixel-level dominant colors\n",
    "    image_features = np.array(image_features)\n",
    "    kmeans_images = KMeans(n_clusters=n_clusters, random_state=42).fit(image_features)\n",
    "    labels = kmeans_images.labels_\n",
    "    \n",
    "    # Organize images into clusters\n",
    "    for cluster_idx in range(n_clusters):\n",
    "        cluster_folder = os.path.join(folder_path, f\"image_cluster_{cluster_idx}\")\n",
    "        os.makedirs(cluster_folder, exist_ok=True)\n",
    "        \n",
    "        for img, label in zip(image_files, labels):\n",
    "            if label == cluster_idx:\n",
    "                img_path = os.path.join(folder_path, img)\n",
    "                output_path = os.path.join(cluster_folder, img)\n",
    "                Image.open(img_path).save(output_path)\n",
    "\n",
    "# Usage\n",
    "cluster_images_by_pixels('Covers 180/', n_clusters=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
